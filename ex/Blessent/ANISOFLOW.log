************************************************************************************************************************
***             WIDEN YOUR WINDOW TO 120 CHARACTERS.  Use 'enscript -r -fCourier9' to print this document            ***
************************************************************************************************************************

---------------------------------------------- PETSc Performance Summary: ----------------------------------------------

./../../src/ANISOFLOW.exe                                                                                                                                                                                                                                       ¬§Þ[ÿ on a arch-osx-mpich-1-hdf5-x-PETSC3.7 named Santiagos-MacBook-Air.local with 2 processors, by sospinar Mon May 16 23:22:50 2016
Using Petsc Release Version 3.7.0, unknown 

                         Max       Max/Min        Avg      Total 
Time (sec):           1.061e+00      1.00000   1.061e+00
Objects:              2.900e+01      1.00000   2.900e+01
Flops:                0.000e+00      0.00000   0.000e+00  0.000e+00
Flops/sec:            0.000e+00      0.00000   0.000e+00  0.000e+00
Memory:               9.135e+06      1.30072              1.616e+07
MPI Messages:         9.500e+00      1.18750   8.750e+00  1.750e+01
MPI Message Lengths:  8.920e+05      1.00002   1.019e+05  1.784e+06
MPI Reductions:       1.180e+02      1.00000

Flop counting convention: 1 flop = 1 real number operation of type (multiply/divide/add/subtract)
                            e.g., VecAXPY() for real vectors of length N --> 2N flops
                            and VecAXPY() for complex vectors of length N --> 8N flops

Summary of Stages:   ----- Time ------  ----- Flops -----  --- Messages ---  -- Message Lengths --  -- Reductions --
                        Avg     %Total     Avg     %Total   counts   %Total     Avg         %Total   counts   %Total 
 0:      Main Stage: 3.6869e-04   0.0%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 
 1:     GetGeometry: 8.0203e-01  75.6%  0.0000e+00   0.0%  8.000e+00  45.7%  7.591e+03        7.4%  7.300e+01  61.9% 
 2:  GetProrperties: 2.5041e-01  23.6%  0.0000e+00   0.0%  4.500e+00  25.7%  9.413e+04       92.3%  9.000e+00   7.6% 
 3:           GetBC: 6.2075e-03   0.6%  0.0000e+00   0.0%  5.000e+00  28.6%  2.201e+02        0.2%  3.000e+01  25.4% 
 4:       DestroyBC: 7.4745e-04   0.1%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  4.000e+00   3.4% 
 5: DestroyProperties: 3.3801e-04   0.0%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 
 6: DestroyGeometry: 1.3387e-03   0.1%  0.0000e+00   0.0%  0.000e+00   0.0%  0.000e+00        0.0%  0.000e+00   0.0% 

------------------------------------------------------------------------------------------------------------------------
See the 'Profiling' chapter of the users' manual for details on interpreting output.
Phase summary info:
   Count: number of times phase was executed
   Time and Flops: Max - maximum over all processors
                   Ratio - ratio of maximum to minimum over all processors
   Mess: number of messages sent
   Avg. len: average message length (bytes)
   Reduct: number of global reductions
   Global: entire computation
   Stage: stages of a computation. Set stages with PetscLogStagePush() and PetscLogStagePop().
      %T - percent time in this phase         %F - percent flops in this phase
      %M - percent messages in this phase     %L - percent message lengths in this phase
      %R - percent reductions in this phase
   Total Mflop/s: 10e-6 * (sum of flops over all processors)/(max time over all processors)
------------------------------------------------------------------------------------------------------------------------


      ##########################################################
      #                                                        #
      #                          WARNING!!!                    #
      #                                                        #
      #   This code was compiled with a debugging option,      #
      #   To get timing results run ./configure                #
      #   using --with-debugging=no, the performance will      #
      #   be generally two or three times faster.              #
      #                                                        #
      ##########################################################


Event                Count      Time (sec)     Flops                             --- Global ---  --- Stage ---   Total
                   Max Ratio  Max     Ratio   Max  Ratio  Mess   Avg len Reduct  %T %F %M %L %R  %T %F %M %L %R Mflop/s
------------------------------------------------------------------------------------------------------------------------

--- Event Stage 0: Main Stage


--- Event Stage 1: GetGeometry

VecSet                 4 1.0 9.7735e-04 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyBegin       3 1.0 2.7556e-05 1.2 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyEnd         3 1.0 2.6814e-05 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecScatterBegin        3 1.0 7.2027e-03 1.2 0.00e+00 0.0 4.0e+00 2.7e+04 0.0e+00  1  0 23  6  0   1  0 50 80  0     0
VecScatterEnd          3 1.0 2.1258e-03 3.5 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0

--- Event Stage 2: GetProrperties

BuildTwoSidedF         1 1.0 3.7302e-02 8.6 0.00e+00 0.0 2.5e+00 6.4e+05 0.0e+00  2  0 14 89  0   8  0 56 97  0     0
VecMax                 1 1.0 2.7153e-03 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 2.0e+00  0  0  0  0  2   1  0  0  0 22     0
VecSet                 1 1.0 8.1077e-04 1.1 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0
VecAssemblyBegin       1 1.0 2.4240e-01 8.3 0.00e+00 0.0 2.5e+00 6.4e+05 2.0e+00 13  0 14 89  2  54  0 56 97 22     0
VecAssemblyEnd         1 1.0 8.9075e-03 7.4 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   2  0  0  0  0     0
VecScatterBegin        1 1.0 1.0714e-03 1.0 0.00e+00 0.0 2.0e+00 2.7e+04 0.0e+00  0  0 11  3  0   0  0 44  3  0     0
VecScatterEnd          1 1.0 4.9249e-05 1.0 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   0  0  0  0  0     0

--- Event Stage 3: GetBC

BuildTwoSidedF         6 1.0 4.2702e-04 1.0 0.00e+00 0.0 5.0e+00 7.7e+02 0.0e+00  0  0 29  0  0   7  0100100  0     0
VecAssemblyBegin       6 1.0 4.6917e-03 5.8 0.00e+00 0.0 5.0e+00 7.7e+02 1.2e+01  0  0 29  0 10  44  0100100 40     0
VecAssemblyEnd         6 1.0 1.3666e-04 1.3 0.00e+00 0.0 0.0e+00 0.0e+00 0.0e+00  0  0  0  0  0   2  0  0  0  0     0

--- Event Stage 4: DestroyBC


--- Event Stage 5: DestroyProperties


--- Event Stage 6: DestroyGeometry

------------------------------------------------------------------------------------------------------------------------

Memory usage is given in bytes:

Object Type          Creations   Destructions     Memory  Descendants' Mem.
Reports information only for process 0.

--- Event Stage 0: Main Stage


--- Event Stage 1: GetGeometry

              Vector     8              4      2185048     0.
      Vector Scatter     1              0            0     0.
    Distributed Mesh     1              0            0     0.
Star Forest Bipartite Graph     2              0            0     0.
     Discrete System     1              0            0     0.
           Index Set     6              2       559480     0.
   IS L to G Mapping     1              0            0     0.

--- Event Stage 2: GetProrperties

              Vector     2              1      1090936     0.

--- Event Stage 3: GetBC

              Vector     6              0            0     0.

--- Event Stage 4: DestroyBC

              Vector     0              3         6224     0.
              Viewer     1              0            0     0.

--- Event Stage 5: DestroyProperties

              Vector     0              1      1229264     0.

--- Event Stage 6: DestroyGeometry

              Vector     0              4      1235496     0.
      Vector Scatter     0              1      1090360     0.
    Distributed Mesh     0              1         5072     0.
Star Forest Bipartite Graph     0              2         1696     0.
     Discrete System     0              1          864     0.
           Index Set     0              4         4384     0.
   IS L to G Mapping     0              1       614492     0.
========================================================================================================================
Average time to get PetscTime(): 3.95e-08
Average time for MPI_Barrier(): 2.7056e-06
Average time for zero size MPI_Send(): 1.8876e-05
#PETSc Option Table entries:
-Input_dir in/
-Input_file_bc BCtempDT
-Input_file_cvt matrix.mprops
-Input_file_cvt_by_zones tsim_USMH.asc
-Input_file_gmtry tsim_USMH.asc
-Input_type 1
-log_view ascii:ANISOFLOW.log
-Ouput_dir out/
-Ouput_type 1
-Run_options_scheme 2
-Run_options_time 0
#End of PETSc Option Table entries
Compiled without FORTRAN kernels
Compiled with full precision matrices (default)
sizeof(short) 2 sizeof(int) 4 sizeof(long) 8 sizeof(void*) 8 sizeof(PetscScalar) 8 sizeof(PetscInt) 4
Configure options: --with-debugging=1 --with-cxx=0 -with-x --download-hdf5=1
-----------------------------------------
Libraries compiled on Wed May 11 17:28:08 2016 on Santiagos-MacBook-Air.local 
Machine characteristics: Darwin-15.4.0-x86_64-i386-64bit
Using PETSc directory: /Users/sospinar/Documents/FORTRAN/Librerias/PETSc
Using PETSc arch: arch-osx-mpich-1-hdf5-x-PETSC3.7
-----------------------------------------

Using C compiler: mpicc    -Wall -Wwrite-strings -Wno-strict-aliasing -Wno-unknown-pragmas -fvisibility=hidden -g3  ${COPTFLAGS} ${CFLAGS}
Using Fortran compiler: mpif90   -Wall -ffree-line-length-0 -Wno-unused-dummy-argument -g   ${FOPTFLAGS} ${FFLAGS} 
-----------------------------------------

Using include paths: -I/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/arch-osx-mpich-1-hdf5-x-PETSC3.7/include -I/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/include -I/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/include -I/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/arch-osx-mpich-1-hdf5-x-PETSC3.7/include -I/opt/X11/include -I/Users/sospinar/Documents/FORTRAN/Librerias/MPICH/lib/include
-----------------------------------------

Using C linker: mpicc
Using Fortran linker: mpif90
Using libraries: -Wl,-rpath,/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/arch-osx-mpich-1-hdf5-x-PETSC3.7/lib -L/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/arch-osx-mpich-1-hdf5-x-PETSC3.7/lib -lpetsc -llapack -lblas -Wl,-rpath,/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/arch-osx-mpich-1-hdf5-x-PETSC3.7/lib -L/Users/sospinar/Documents/FORTRAN/Librerias/PETSc/arch-osx-mpich-1-hdf5-x-PETSC3.7/lib -lhdf5hl_fortran -lhdf5_fortran -lhdf5_hl -lhdf5 -Wl,-rpath,/opt/X11/lib -L/opt/X11/lib -lX11 -Wl,-rpath,/Users/sospinar/Documents/FORTRAN/Librerias/MPICH/lib/lib -L/Users/sospinar/Documents/FORTRAN/Librerias/MPICH/lib/lib -Wl,-rpath,/usr/local/lib/gcc/x86_64-apple-darwin15.0.0/6.1.0 -L/usr/local/lib/gcc/x86_64-apple-darwin15.0.0/6.1.0 -Wl,-rpath,/usr/local/lib -L/usr/local/lib -ldl -lmpifort -lgfortran -lquadmath -lm -Wl,-rpath,/Users/sospinar/Documents/FORTRAN/Librerias/MPICH/lib/lib -L/Users/sospinar/Documents/FORTRAN/Librerias/MPICH/lib/lib -Wl,-rpath,/usr/local/lib/gcc/x86_64-apple-darwin15.0.0/6.1.0 -L/usr/local/lib/gcc/x86_64-apple-darwin15.0.0/6.1.0 -Wl,-rpath,/usr/local/lib -L/usr/local/lib -lmpi -lpmpi -lSystem -lgcc_ext.10.5 -Wl,-rpath,/Users/sospinar/Documents/FORTRAN/Librerias/MPICH/lib/lib -L/Users/sospinar/Documents/FORTRAN/Librerias/MPICH/lib/lib -Wl,-rpath,/usr/local/lib/gcc/x86_64-apple-darwin15.0.0/6.1.0 -L/usr/local/lib/gcc/x86_64-apple-darwin15.0.0/6.1.0 -Wl,-rpath,/usr/local/lib -L/usr/local/lib -ldl 
-----------------------------------------

